{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5490360b-f787-41fb-a5d0-cc3c9562fb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, importlib.util\n",
    "!pip install --upgrade -qqq uv\n",
    "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):    \n",
    "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
    "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
    "    !uv pip install -qqq \\\n",
    "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n",
    "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
    "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
    "        git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels\n",
    "elif importlib.util.find_spec(\"unsloth\") is None:\n",
    "    !uv pip install -qqq unsloth\n",
    "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo huggingface-hub==0.34.4 datasets==4.3.0 numpy==2.3.4 pandas==2.3.3 pyarrow==22.0.0 tqdm==4.67.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445d65cf-5d7e-4ac6-aba8-ea3bc63b6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                          4.3.0\n",
      "fastrlock                         0.8.3\n",
      "huggingface-hub                   0.34.4\n",
      "numpy                             2.3.4\n",
      "pandas                            2.3.3\n",
      "pyarrow                           22.0.0\n",
      "tokenizers                        0.22.1\n",
      "tqdm                              4.67.1\n",
      "transformers                      4.56.2\n",
      "trl                               0.22.2\n",
      "unsloth                           2025.11.2\n",
      "unsloth_zoo                       2025.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"datasets|pandas|tqdm|numpy|pyarrow|transformers|tokenizers|trl|unsloth|unsloth_zoo|huggingface-hub|datasets|numpy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1277b61f-f0c5-4d71-851e-94b8c08bbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8016aa-48d5-4f1f-9d89-b9d2081a10e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe3b0a8945b452db9759d531eb3c616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51802737-18c7-4b3e-9edc-7debd0ac77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Starting dataset loading process and inspection...\n",
      "\n",
      "-> Loading and selecting 15% randomly from databricks/databricks-dolly-15k (train)\n",
      "\n",
      "-> Loading and selecting 1% randomly from HuggingFaceH4/ultrachat_200k (train_sft)\n",
      "\n",
      "-> Loading and selecting 40% randomly from open-thoughts/open-thoughts-114k (train)\n",
      "\n",
      "-> Loading and selecting 5% randomly from tatsu-lab/alpaca (train)\n",
      "\n",
      "-> Loading and selecting 30% randomly from google/boolq (train)\n",
      "\n",
      "-> Loading and selecting 8% randomly from lmsys/chatbot_arena_conversations (train)\n",
      "\n",
      "üß† Applying OpenThoughts formatter...\n",
      "\n",
      "üß† Applying gsm8k formatter...\n",
      "\n",
      "üß† Applying LMSYS winner extraction logic...\n",
      "\n",
      "üß† Applying dolly formatter...\n",
      "\n",
      "üß† Applying ultrachat formatter...\n",
      "\n",
      "üß† Formatting math formatter...\n",
      "\n",
      "üß† Formatting alpaca formatter...\n",
      "\n",
      "üß† Formatting boolq formatter...\n",
      "\n",
      "üß† Formatting arc formatter...\n",
      "\n",
      "üß† Formatting arc formatter...\n",
      "üóëÔ∏è Applying quality filter...\n",
      "\n",
      "‚úÖ Final dataset successfully filtered and shuffled.\n",
      "--- Entry 1 ---\n",
      "Message with chat template: <|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-11-08\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
      "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n",
      "\n",
      "You are a highly professional, concise technical expert across modern computing domains ‚Äî \n",
      "including software architecture, cloud infrastructure, data systems, machine learning, and applied AI.\n",
      "\n",
      "Your task is to:\n",
      "- Answer the user‚Äôs question using the provided CONTEXT as your primary source.\n",
      "- If the CONTEXT does not contain enough information, use your own knowledge,\n",
      "  but clearly distinguish between context-based and general reasoning.\n",
      "\n",
      "Your responses must be:\n",
      "- Structured ‚Äî use clear formatting and logical reasoning.\n",
      "- Contextual ‚Äî rely only on the information available.\n",
      "- Concise ‚Äî eliminate filler words while preserving precision.\n",
      "- Aligned with industry best practices ‚Äî modern, reproducible, and standards-based.\n",
      "<|end|><|start|>user<|message|>Compile a visually appealing list of at least ten distinctive dips and gravies that can be paired with a range of dishes prepared on your electric griddle. Make sure to include both sweet and savory options, as well as dips that cater to different dietary restrictions such as vegan, gluten-free, or low-fat. Additionally, provide brief descriptions of each dip or gravy highlighting its key ingredients, flavor profile, and suggested griddle dishes to accompany it.<|end|><|start|>assistant<|message|>1. Caramelized Onion and Garlic Dip - This savory dip pairs perfectly with breakfast dishes such as eggs, bacon, and pancakes or can be used as a topping for burgers and sandwiches. It is made with caramelized onions, garlic, cream cheese, and sour cream, and has a sweet and tangy flavor.\n",
      " \n",
      "2. Spicy Avocado Dip - This vegan option is perfect for those looking for a healthy dip option. Made with ripe avocados, jalapenos, lime juice, and cilantro, it is a great accompaniment for veggie fajitas or as a topping for grilled chicken or fish.\n",
      "\n",
      "3. Sweet and Sour Dipping Sauce - This tangy sauce is great for dipping crispy chicken tenders or fried shrimp. Made with ketchup, brown sugar, apple cider vinegar, soy sauce, and garlic, it has a sweet and slightly sour flavor that complements fried foods well.\n",
      "\n",
      "4. Bacon and Cheddar Dip - This savory dip pairs well with baked potatoes and grilled meats. Made with chopped bacon, cheddar cheese, sour cream, and Worcestershire sauce, it has a rich and creamy texture with a smoky flavor.\n",
      "\n",
      "5. Chipotle Mayo Dip - This spicy dip is perfect for dipping sweet potato fries or as a topping for burgers or sandwiches. Made with mayonnaise, chipotle chilies, lime juice, and garlic, it has a smoky and spicy flavor.\n",
      "\n",
      "6. Cheesy Queso Dip - This gluten-free dip is great for dipping tortilla chips or as a topping for nachos. Made with Velveeta cheese, diced tomatoes, and green chilies, it has a creamy and cheesy flavor with a slight kick.\n",
      "\n",
      "7. Low-Fat Ranch Dip - This healthy dip is made with Greek yogurt, garlic, and fresh herbs, and is a great pairing for grilled veggies, chicken, or fish.\n",
      "\n",
      "8. Roasted Red Pepper Dip - This vegan dip is a great pairing for grilled vegetables, flatbreads, or grilled chicken. Made with roasted red peppers, garlic, and olive oil, it has a smoky and slightly sweet flavor.\n",
      "\n",
      "9. Cilantro Lime Aioli - This low-fat dip is great for dipping crunchy onion rings or as a topping for grilled chicken or fish. Made with Greek yogurt, lime juice, and fresh cilantro, it has a tangy and slightly spicy flavor.\n",
      "\n",
      "10. Chocolate Ganache - This sweet dip is perfect for dipping fresh fruit or as a topping for pancakes, waffles, or French toast. Made with dark chocolate and heavy cream, it has a rich and decadent chocolate flavor.<|return|>...\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--- Entry 2 ---\n",
      "Message with chat template: <|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-11-08\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
      "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n",
      "\n",
      "You are a highly professional, concise technical expert across modern computing domains ‚Äî \n",
      "including software architecture, cloud infrastructure, data systems, machine learning, and applied AI.\n",
      "\n",
      "Your task is to:\n",
      "- Answer the user‚Äôs question using the provided CONTEXT as your primary source.\n",
      "- If the CONTEXT does not contain enough information, use your own knowledge,\n",
      "  but clearly distinguish between context-based and general reasoning.\n",
      "\n",
      "Your responses must be:\n",
      "- Structured ‚Äî use clear formatting and logical reasoning.\n",
      "- Contextual ‚Äî rely only on the information available.\n",
      "- Concise ‚Äî eliminate filler words while preserving precision.\n",
      "- Aligned with industry best practices ‚Äî modern, reproducible, and standards-based.\n",
      "<|end|><|start|>user<|message|>Please write a C++ function that takes an array as input and finds the length of the longest continuous subsequence in the array where each number is greater than the previous one. The function should return an integer which represents the length of the longest increasing subsequence. Please ensure that your function takes into account edge cases where the array is empty or has only one element. Please make sure to use appropriate variable names and comments where necessary for clarity.<|end|><|start|>assistant<|message|>Here's a possible implementation of the function:\n",
      "\n",
      "```c++\n",
      "int longestIncreasingSubsequence(int* arr, int size) {\n",
      "    if (size < 2) { // edge cases\n",
      "        return size; // either 0 or 1\n",
      "    }\n",
      "\n",
      "    int maxLength = 1; // initialize with 1 (the minimum)\n",
      "    int currentLength = 1; // the length of the current subsequence\n",
      "\n",
      "    for (int I = 1; I < size; i++) {\n",
      "        if (arr[i] > arr[i-1]) { // the next element is greater\n",
      "            currentLength++; // extend the subsequence\n",
      "        } else { // the next element is not greater\n",
      "            maxLength = max(maxLength, currentLength); // update the max length\n",
      "            currentLength = 1; // reset the current length\n",
      "        }\n",
      "    }\n",
      "\n",
      "    return max(maxLength, currentLength); // don't forget the last subsequence\n",
      "}\n",
      "```\n",
      "\n",
      "Here's how the function works:\n",
      "\n",
      "1. It first checks if the array is empty or has only one element, in which case it returns the size of the array (0 or 1).\n",
      "2. It initializes two variables: one to keep track of the current length of the increasing subsequence (starts at 1) and one to keep track of the maximum length (also starts at 1, as the first element is always an increasing subsequence).\n",
      "3. It then iterates over the array, comparing each element with the previous one. If the next element is greater, it extends the current subsequence by incrementing the length. If it's not greater, it means the current subsequence ends, so the function updates the maximum length with the current length (if it's greater) and resets the current length to 1, as the next element could be the start of a new subsequence.\n",
      "4. After the loop, the function returns the maximum length between the maximum length found so far and the last current length (which could be a subsequence at the end of the array).\n",
      "\n",
      "Note that this implementation has a time complexity of O(n) and a space complexity of O(1), as it only uses a constant amount of additional memory. Also, the input array is assumed to be sorted in increasing order. If it's not, the function could be modified to sort the array first, but that would increase the time complexity to O(n log n).<|return|>...\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--- Entry 3 ---\n",
      "Message with chat template: <|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-11-08\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
      "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n",
      "\n",
      "You are a highly professional, concise technical expert across modern computing domains ‚Äî \n",
      "including software architecture, cloud infrastructure, data systems, machine learning, and applied AI.\n",
      "\n",
      "Your task is to:\n",
      "- Answer the user‚Äôs question using the provided CONTEXT as your primary source.\n",
      "- If the CONTEXT does not contain enough information, use your own knowledge,\n",
      "  but clearly distinguish between context-based and general reasoning.\n",
      "\n",
      "Your responses must be:\n",
      "- Structured ‚Äî use clear formatting and logical reasoning.\n",
      "- Contextual ‚Äî rely only on the information available.\n",
      "- Concise ‚Äî eliminate filler words while preserving precision.\n",
      "- Aligned with industry best practices ‚Äî modern, reproducible, and standards-based.\n",
      "<|end|><|start|>user<|message|>Return your final response within \\boxed{}. The number of points that are equidistant from both a circle and its two parallel tangents is\n",
      "(A) 0.\n",
      "(B) 2.\n",
      "(C) 3.\n",
      "(D) 4.\n",
      "(E) Infinitely many.\n",
      "(The 20th Annual American High School Mathematics Examination, 1969)<|end|><|start|>assistant<|message|>Okay, let's see. The problem is asking about the number of points that are equidistant from both a circle and its two parallel tangents. The options are from 0 to infinitely many. Hmm. I need to visualize this first.\n",
      "\n",
      "So, imagine a circle. Let me recall that a tangent to a circle is a line that touches the circle at exactly one point. If there are two parallel tangents, then the circle must be between these two lines, right? Since parallel lines never meet, the distance between them must be twice the radius of the circle. Wait, is that true?\n",
      "\n",
      "Wait, no. If the circle is in between two parallel tangent lines, then the distance between the two lines would be twice the diameter, right? Because the tangent lines are each a distance of the radius away from the center, but on opposite sides. Wait, maybe I need to think more carefully.\n",
      "\n",
      "Let me sketch this in my mind. Suppose the circle has center O and radius r. The two parallel tangent lines must be on opposite sides of the circle. For a circle, the distance from the center to a tangent line is equal to the radius. So, if there are two parallel tangents, one on each side of the circle, then the distance between these two lines is 2r. Because each tangent is r distance away from the center, and since they're parallel, the total distance between them is 2r. Got that.\n",
      "\n",
      "Now, the question is about points equidistant from the circle and both of these two parallel tangents. Wait, equidistant from the circle and both tangents? Wait, the points must be equidistant to the circle and to each of the two tangent lines? Or equidistant to the circle and to both tangents collectively? Hmm, the wording is a bit ambiguous, but I think it's equidistant to the circle and to both of the two parallel tangents. Wait, that might not make sense. Because the two tangents are on opposite sides of the circle, so a point can't be equidistant to both tangents unless it's somewhere between them. But the circle is in between them. So maybe the problem is asking for points that are equidistant to the circle and to each of the two tangents. Wait, that might not be possible. Let me parse the question again.\n",
      "\n",
      "\"The number of points that are equidistant from both a circle and its two parallel tangents is...\"\n",
      "\n",
      "Wait, \"equidistant from both a circle and its two parallel tangents.\" So, the point is equidistant from the circle and from both of the two parallel tangents. So, the point must have equal distance to the circle and to each tangent line? Wait, but the two tangent lines are parallel, so a point equidistant to both tangents would lie on the line midway between them. Since the distance between the tangents is 2r, the midway line is at distance r from each tangent, which is the same as the radius. Wait, so the center of the circle is on this midway line, and the distance from the center to each tangent is r. But the circle itself is at radius r from the center, so points on the circle are at distance zero from the circle (since they are on it) and distance r from the tangent lines. But the problem is asking for points equidistant from the circle and the two tangents. Hmm.\n",
      "\n",
      "Wait, perhaps the points need to be equidistant to the circle and to both tangent lines. So, the distance from the point to the circle is equal to the distance from the point to each tangent line. Wait, but the distance from a point to a circle is the minimal distance to the circle, which would be |distance from point to center minus radius|. Whereas the distance from the point to each tangent line is a fixed value if the point is equidistant to both tangents. Let me formalize this.\n",
      "\n",
      "Let me set up a coordinate system. Let's assume the circle is centered at (0, 0) with radius r. The two parallel tangent lines would then be horizontal lines y = r and y = -r, since the distance from the center to each tangent is r. Wait, but if the circle is centered at (0,0), then the horizontal tangents would be y = r and y = -r. The distance between these two lines is 2r.\n",
      "\n",
      "Now, we need to find points equidistant from the circle and both tangents. Since the two tangents are y = r and y = -r, the set of points equidistant from both tangents would lie on the lines midway between them. The midway line between y = r and y = -r is y = 0, which is the x-axis. So, any point equidistant from both tangents must lie on the x-axis.\n",
      "\n",
      "But we also need these points to be equidistant from the circle. The distance from a point (x, 0) on the x-axis to the circle would be the minimal distance from (x, 0) to any point on the circle. The minimal distance is |distance from (x,0) to the center (0,0) minus the radius|. The distance from (x,0) to the center is |x|. So, the minimal distance to the circle is ||x| - r|.\n",
      "\n",
      "On the other hand, the distance from (x,0) to each tangent line y = r and y = -r is r, since the vertical distance from (x,0) to y = r is r, and similarly to y = -r is also r. Wait, but if the point is on the x-axis, then the distance to both tangents is r. So, the distance from any point on the x-axis to the two tangents is always r. Therefore, we need points on the x-axis where the distance to the circle is also r.\n",
      "\n",
      "So, set ||x| - r| = r. Let's solve this equation.\n",
      "\n",
      "Case 1: |x| - r = r => |x| = 2r. So, x = 2r or x = -2r.\n",
      "\n",
      "Case 2: -(|x| - r) = r => -|x| + r = r => -|x| = 0 => |x| = 0. So, x = 0.\n",
      "\n",
      "Therefore, the points on the x-axis that are equidistant from the circle and the two tangents are at (2r, 0), (-2r, 0), and (0,0). So, three points. Therefore, the answer is C) 3.\n",
      "\n",
      "Wait, but let me verify. The point (0,0) is the center. The distance from (0,0) to the circle is the radius r (since the center is inside the circle, the minimal distance to the circle would be r - 0 = r). The distance from (0,0) to each tangent is r. So, yes, (0,0) is equidistant to the circle and the tangents.\n",
      "\n",
      "The points (2r, 0) and (-2r, 0) are outside the circle. The distance from (2r, 0) to the circle is |2r - r| = r. The distance to each tangent is r. Similarly for (-2r, 0). So those three points satisfy the condition. Therefore, the answer should be 3, which is option C.\n",
      "\n",
      "But let me check again. Maybe there are more points. Wait, the problem says \"points equidistant from both a circle and its two parallel tangents\". So, the points must be equidistant to the circle and to both tangents. But in our analysis, we restricted to points on the x-axis, since they have to be equidistant to both tangents. Because the two tangents are parallel and on opposite sides, the set of points equidistant to both is the midline between them, which is the x-axis. Therefore, all candidate points must lie on the x-axis. Then, on the x-axis, we found three points: center and two points at distance 2r from the center.\n",
      "\n",
      "But wait, let's think if there are points not on the x-axis. Wait, but if a point is not on the x-axis, then its distance to the two tangents would not be equal. For example, take a point above the x-axis. Its distance to the upper tangent y = r would be less than its distance to the lower tangent y = -r. Similarly, a point below the x-axis would be closer to the lower tangent. Therefore, the only points equidistant to both tangents are on the x-axis. So, indeed, the only possible points are on the x-axis. Therefore, we only need to consider points on the x-axis. And there we found three points. So, the answer should be C) 3.\n",
      "\n",
      "But wait, let's consider the point (0,0). The distance from (0,0) to the circle is r (since it's the center, the minimal distance to the circle is the radius). The distance from (0,0) to each tangent is r. So, yes, (0,0) is equidistant to the circle and the tangents.\n",
      "\n",
      "The points (2r, 0) and (-2r, 0): distance to the circle is |2r - r| = r, and distance to each tangent is r. So, those two points work too.\n",
      "\n",
      "Is there any other point on the x-axis where ||x| - r| = r? Let's check. Solving ||x| - r| = r:\n",
      "\n",
      "If |x| >= r, then |x| - r = r => |x| = 2r, so x = ¬±2r.\n",
      "\n",
      "If |x| < r, then -( |x| - r ) = r => -|x| + r = r => |x| = 0 => x = 0.\n",
      "\n",
      "Therefore, only three solutions. So, only three points. So, answer is C) 3.\n",
      "\n",
      "But wait, let me think differently. Suppose the circle is not between the two parallel tangents. Wait, but if the two lines are parallel tangents to the circle, then they must be on opposite sides of the circle. Otherwise, if they are on the same side, the lines would have to be coinciding to both be tangent, which is not possible for parallel lines. So, the two parallel tangents must be on opposite sides, separated by 2r.\n",
      "\n",
      "Alternatively, if the circle is, say, between two vertical parallel tangents, then similar reasoning applies. The set of points equidistant to both tangents would be the vertical line halfway between them, which would pass through the center of the circle, and same thing: three points. So, regardless of orientation, the answer is three.\n",
      "\n",
      "Wait, but maybe in 3D, but the problem is in plane. So, yes, three points.\n",
      "\n",
      "Wait, but maybe I missed something. Let me think again.\n",
      "\n",
      "Suppose the circle is centered at (0,0) with radius r. The two parallel tangents are y = r and y = -r.\n",
      "\n",
      "Set of points equidistant to both tangents: y = 0.\n",
      "\n",
      "On y=0, find points where distance to circle is equal to distance to tangent (which is r). The distance from a point (x,0) to the circle is the minimal distance to the circle, which is |sqrt(x¬≤ + 0¬≤) - r| = | |x| - r |.\n",
      "\n",
      "Set this equal to r: | |x| - r | = r.\n",
      "\n",
      "Solutions:\n",
      "\n",
      "Case 1: |x| - r = r => |x| = 2r => x = ¬±2r.\n",
      "\n",
      "Case 2: -(|x| - r) = r => -|x| + r = r => |x| = 0 => x=0.\n",
      "\n",
      "Thus, three points: (0,0), (2r,0), (-2r,0). Therefore, 3 points. So, answer is C.\n",
      "\n",
      "But let me check with a specific example. Let r = 1. Then the circle is x¬≤ + y¬≤ = 1. The tangents are y=1 and y=-1.\n",
      "\n",
      "Points equidistant to both tangents lie on y=0. On y=0, the distance to the circle is | |x| - 1 |. Set this equal to 1.\n",
      "\n",
      "Solutions:\n",
      "\n",
      "| |x| - 1 | = 1.\n",
      "\n",
      "Case 1: |x| - 1 = 1 => |x| = 2 => x=2 or x=-2.\n",
      "\n",
      "Case 2: -(|x| -1 ) =1 => -|x| +1 =1 => |x|=0 => x=0.\n",
      "\n",
      "Thus, points (0,0), (2,0), (-2,0). Indeed three points. So, in this case, three points. Therefore, the answer is C)3.\n",
      "\n",
      "But wait, let me check if (0,0) is actually equidistant to the circle and the tangents. The distance from (0,0) to the circle is the radius, which is 1. The distance from (0,0) to the tangents y=1 and y=-1 is 1. So, yes, it is equidistant.\n",
      "\n",
      "For (2,0): distance to circle is |2 -1|=1, and distance to the tangents is 1. Similarly for (-2,0). So, all three points satisfy.\n",
      "\n",
      "Therefore, the answer is C.\n",
      "\n",
      "**Final Answer**\n",
      "\\boxed{C}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "To determine the number of points equidistant from both a circle and its two parallel tangents, we start by considering a circle with center \\(O\\) and radius \\(r\\). The two parallel tangents are on opposite sides of the circle, each at a distance \\(r\\) from the center. The distance between these two tangents is \\(2r\\).\n",
      "\n",
      "The set of points equidistant from both tangents lies on the line midway between them, which is the line passing through the center of the circle. For a circle centered at \\((0, 0)\\) with radius \\(r\\), the tangents are \\(y = r\\) and \\(y = -r\\), and the midway line is \\(y = 0\\) (the x-axis).\n",
      "\n",
      "Next, we need to find points on the x-axis that are also equidistant from the circle. The distance from a point \\((x, 0)\\) on the x-axis to the circle is given by \\(||x| - r|\\). This distance must equal the distance from the point to the tangents, which is \\(r\\).\n",
      "\n",
      "Solving the equation \\(||x| - r| = r\\):\n",
      "\n",
      "1. **Case 1**: \\(|x| - r = r\\)\n",
      "   - \\(|x| = 2r\\)\n",
      "   - Solutions: \\(x = 2r\\) or \\(x = -2r\\)\n",
      "\n",
      "2. **Case 2**: \\(- (|x| - r) = r\\)\n",
      "   - \\(-|x| + r = r\\)\n",
      "   - \\(|x| = 0\\)\n",
      "   - Solution: \\(x = 0\\)\n",
      "\n",
      "Thus, the points \\((2r, 0)\\), \\((-2r, 0)\\), and \\((0, 0)\\) are equidistant from both the circle and the two parallel tangents. These points are verified by checking their distances to the circle and the tangents.\n",
      "\n",
      "Therefore, the number of such points is \\(\\boxed{C}\\).<|return|>...\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "üìä Analyzing Sources in Final Dataset...\n",
      "--------------------------------------------------\n",
      "Final Dataset Size: 29692 entries\n",
      "Total Unique Sources Found: 10\n",
      "--------------------------------------------------\n",
      "Count and Percentage of Data Entries per Source:\n",
      "              Count Percentage\n",
      "OpenThoughts   9987     33.64%\n",
      "GSM8K          7473     25.17%\n",
      "sharegpt4      3582     12.06%\n",
      "boolq          1682      5.66%\n",
      "lmsys_conv     1537      5.18%\n",
      "alpaca         1529      5.15%\n",
      "dolly          1303      4.39%\n",
      "ultrachat      1197      4.03%\n",
      "math            746      2.51%\n",
      "arc             656      2.21%\n",
      "--------------------------------------------------\n",
      "\n",
      "üéâ SUCCESS! Final SFT dataset created: train_sft_final.jsonl\n",
      "Total samples after filtering: 29692\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "INSPECT_ON = False\n",
    "\n",
    "# Prints ONE random entry\n",
    "def inspect_random_entry(ds_name, ds_object, force_disp = False):\n",
    "\n",
    "    if not force_disp:\n",
    "        if not INSPECT_ON:\n",
    "            return \n",
    "    \n",
    "    \"\"\"Randomly selects and prints one raw sample from the dataset for observation.\"\"\"\n",
    "    print(f\"\\n--- INSPECTION: {ds_name} (ONE RANDOM RAW SAMPLE) ---\")\n",
    "    random_index = random.randint(0, len(ds_object) - 1)\n",
    "    sample = ds_object[random_index]\n",
    "    print(f\"Sample Index: {random_index} Raw Data:\")\n",
    "    print(json.dumps(sample, indent=2, default=str))\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "# Prints parts of the formatted datasets\n",
    "def inspect_formatted_sft(ds_name, ds_object, n = 2, disp_len = 50, force_disp = False):\n",
    "\n",
    "    if not force_disp:\n",
    "        if not INSPECT_ON:\n",
    "            return \n",
    "    \n",
    "    for i, entry in enumerate(ds_object):\n",
    "        if i > n:\n",
    "            break\n",
    "        print(f\"--- Entry {i+1} ---\")\n",
    "        print(f\"Instruction: {entry['instruction'][:disp_len]}...\") # Truncating for readability\n",
    "        print(f\"Response: {entry['response'][:disp_len]}\")\n",
    "        print(f\"Source: {entry['source']}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "#  EXTRACTION FUNCTIONS. Convert various of datasets to  { \"instruction\": \"xxx\", \"response\": \"xxx\", \"source\": \"xxx\" }\n",
    "def extract_lmsys_winner(example):\n",
    "    \"\"\"\n",
    "    Identifies the winning conversation (model_a or model_b) and extracts the \n",
    "    first instruction/response pair from that conversation list.\n",
    "    \"\"\"\n",
    "    winner_key = example.get('winner')\n",
    "    \n",
    "    if winner_key == 'model_a':\n",
    "        conv_list = example.get('conversation_a')\n",
    "    elif winner_key == 'model_b':\n",
    "        conv_list = example.get('conversation_b')\n",
    "    else: # Handles 'tie', 'tie (a/b)', or missing winner by defaulting to A\n",
    "        conv_list = example.get('conversation_a')\n",
    "        \n",
    "    if not conv_list or len(conv_list) < 2:\n",
    "        return {\"instruction\": None, \"response\": None}\n",
    "\n",
    "    instruction = conv_list[0]['content'] if conv_list[0]['role'] == 'user' else None\n",
    "    response = conv_list[1]['content'] if conv_list[1]['role'] == 'assistant' else None\n",
    "    \n",
    "    return {\"instruction\": instruction, \"response\": response, \"source\": \"lmsys_conv\"}\n",
    "\n",
    "\n",
    "def format_ultrachat(example):\n",
    "    instruction, response = None, None\n",
    "    \n",
    "    user_messages = [m['content'] for m in example['messages'] if m['role'] == 'user']\n",
    "    model_messages = [m['content'] for m in example['messages'] if m['role'] == 'assistant']\n",
    "    instruction = user_messages[0] if user_messages else None\n",
    "    response = model_messages[0] if model_messages else None\n",
    "    \n",
    "    return {\"instruction\": instruction, \"response\": response, \"source\": \"ultrachat\"}\n",
    "\n",
    "\n",
    "def format_dolly(example):\n",
    "    \"\"\"\n",
    "    Formats a single Dolly 15k entry, integrating 'context' into the 'instruction'\n",
    "    when available. Assumes the primary keys are 'instruction', 'context', and 'response'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Core fields for Dolly (will be None/empty string if not present)\n",
    "    core_instruction = example.get(\"instruction\", \"\")\n",
    "    context = example.get(\"context\", \"\")\n",
    "    response = example.get(\"response\", \"\")\n",
    "    \n",
    "    # Initialize the instruction to be returned\n",
    "    final_instruction = \"\"\n",
    "\n",
    "    # --- 1. Build the Instruction ---\n",
    "    \n",
    "    # Check if context exists and is not just whitespace\n",
    "    if isinstance(context, str) and context.strip():\n",
    "        # Prepend the context to the instruction clearly\n",
    "        final_instruction = (\n",
    "            f\"Context: {context.strip()}\\n\\n\"\n",
    "            f\"Instruction: {core_instruction.strip()}\"\n",
    "        )\n",
    "    elif isinstance(core_instruction, str) and core_instruction.strip():\n",
    "        # If no context, just use the core instruction\n",
    "        final_instruction = core_instruction.strip()\n",
    "    # Note: If both are empty, final_instruction remains \"\" (which will be filtered later).\n",
    "\n",
    "    # --- 2. Keep the Response and Source ---\n",
    "    \n",
    "    if isinstance(response, str):\n",
    "        final_response = response.strip()\n",
    "    else:\n",
    "        final_response = response # Keep None/other type for filtering\n",
    "\n",
    "    return {\n",
    "        \"instruction\": final_instruction, \n",
    "        \"response\": final_response, \n",
    "        \"source\": \"dolly\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "import re \n",
    "# Note: You'd need to ensure 'import re' is at the top of your main script \n",
    "# or use pd.Series as you did before, but the pure Python approach is cleaner.\n",
    "\n",
    "def format_GSM8K(example):\n",
    "    \"\"\"\n",
    "    Formats a single GSM8K entry by extracting the question and cleaning \n",
    "    the step-by-step answer (solution) by removing calculator tokens and \n",
    "    the final answer marker.\n",
    "    \"\"\"\n",
    "    \n",
    "    # GSM8K uses 'question' for instruction and 'answer' for response\n",
    "    instruction = example.get(\"question\")\n",
    "    response = example.get(\"answer\")\n",
    "\n",
    "    if isinstance(response, str):\n",
    "        # --- FINAL FIXES FOR GSM8K using pure Python re module ---\n",
    "        \n",
    "        # 1. Remove GSM8K Calculator Tokens (e.g., <<16+20=36>>)\n",
    "        # The re.sub is much cleaner than the pd.Series chaining.\n",
    "        response = re.sub(r'<<.*?>>', '', response).strip()\n",
    "\n",
    "        # 2. Remove the GSM8K Final Answer Marker (e.g., #### 40 or #### 12.5)\n",
    "        # Using [^\\n]+ to catch any numerical/decimal/fractional answer following the marker\n",
    "        response = re.sub(r'####\\s*[^\\n]+', '', response).strip()\n",
    "    \n",
    "    # The 'instruction' only needs to be the question\n",
    "    if isinstance(instruction, str):\n",
    "        instruction = instruction.strip()\n",
    "    \n",
    "    return {\"instruction\": instruction, \"response\": response, \"source\": \"GSM8K\"}\n",
    "\n",
    "def format_OpenThoughts(example):\n",
    "    instruction, response = None, None\n",
    "\n",
    "    # Check for the 'conversations' key typical of OpenThoughts structure\n",
    "    if 'conversations' in example and isinstance(example['conversations'], list):\n",
    "        # The user's instruction is the 'value' of the first 'user' turn\n",
    "        # 1. Extract Instruction (User's turn)\n",
    "        user_turn = next((c for c in example['conversations'] if c['from'] == 'user'), None)\n",
    "        if user_turn:\n",
    "            instruction = user_turn.get('value')\n",
    "\n",
    "        # 2. Extract Response (Assistant's turn)\n",
    "        assistant_turn = next((c for c in example['conversations'] if c['from'] == 'assistant'), None)\n",
    "        if assistant_turn:\n",
    "            response = assistant_turn.get('value')\n",
    "    \n",
    "\n",
    "    if isinstance(response, str):\n",
    "        # Apply the CoT cleaning logic\n",
    "        response = response.replace(\"<|begin_of_thought|>\", \"\").replace(\"<|end_of_thought|>\", \"\").strip()\n",
    "        response = response.replace(\"<|begin_of_solution|>\", \"\").replace(\"<|end_of_solution|>\", \"\").strip()\n",
    "    \n",
    "    return {\"instruction\": instruction, \"response\": response, \"source\": \"OpenThoughts\"}    \n",
    "    \n",
    "def format_math(example):\n",
    "    \n",
    "    return {\"instruction\": example[\"problem\"], \"response\": example[\"solution\"], \"source\": \"math\"}\n",
    "\n",
    "\n",
    "def format_alpaca(example):\n",
    "    \n",
    "    # Base instruction\n",
    "    inst = example.get(\"instruction\", \"\").strip()\n",
    "    inp = example.get(\"input\", \"\")\n",
    "    out = example.get(\"output\") or example.get(\"response\") or example.get(\"answer\") or \"\"\n",
    "\n",
    "    # If input exists and is non-empty, append it with a label\n",
    "    if isinstance(inp, str) and inp.strip():\n",
    "        inst = f\"{inst}\\n\\nInput:\\n{inp.strip()}\"\n",
    "\n",
    "    # final cleaning\n",
    "    inst = inst.strip()\n",
    "    out = out.strip()\n",
    "\n",
    "    return {\"instruction\": inst, \"response\": out, \"source\": \"alpaca\"}\n",
    "\n",
    "\n",
    "def format_sharegpt(example):\n",
    "    \n",
    "    if \"conversations\" not in example or len(example[\"conversations\"]) < 2:\n",
    "        return {\"instruction\": None, \"response\": None}\n",
    "    convs = example[\"conversations\"]\n",
    "    user_turns = [c[\"value\"] for c in convs if c[\"from\"] == \"human\"]\n",
    "    assistant_turns = [c[\"value\"] for c in convs if c[\"from\"] == \"gpt\"]\n",
    "    \n",
    "    return {\n",
    "        \"instruction\": user_turns[0] if user_turns else None,\n",
    "        \"response\": assistant_turns[0] if assistant_turns else None,\n",
    "    }\n",
    "    \n",
    "def format_boolq(example):\n",
    "    \n",
    "    q = example.get(\"question\", \"\").strip()\n",
    "    p = example.get(\"passage\", \"\").strip()\n",
    "    a = example.get(\"answer\", None)\n",
    "\n",
    "    # Convert boolean answer to natural language\n",
    "    if a is True:\n",
    "        answer_text = \"Yes\"\n",
    "    elif a is False:\n",
    "        answer_text = \"No\"\n",
    "    else:\n",
    "        answer_text = \"\"\n",
    "\n",
    "    # Build structured instruction\n",
    "    if p:\n",
    "        instruction = f\"Question: {q}\\n\\nContext:\\n{p}\"\n",
    "    else:\n",
    "        instruction = f\"Question: {q}\"\n",
    "\n",
    "    return {\"instruction\": instruction.strip(), \"response\": answer_text.strip(), \"source\": \"boolq\"}\n",
    "\n",
    "def format_arc(sample):\n",
    "    \"\"\"\n",
    "    Converts a single sample from the allenai/ai2_arc dataset into \n",
    "    the Supervised Fine-Tuning (SFT) instruction-response format.\n",
    "\n",
    "    Args:\n",
    "        sample (dict): A single dictionary sample from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary in the SFT format {\"instruction\": ..., \"response\": ...}.\n",
    "    \"\"\"\n",
    "    # 1. Extract the main question and the answer key\n",
    "    question = sample['question']\n",
    "    answer_key = sample['answerKey']\n",
    "    \n",
    "    # 2. Extract the choices and labels\n",
    "    choices_text = sample['choices']['text']\n",
    "    choices_label = sample['choices']['label']\n",
    "    \n",
    "    # 3. Create the formatted list of choices (e.g., \"A. pulley.\\nB. lever.\\n...\")\n",
    "    formatted_choices = []\n",
    "    # Use zip to pair the labels (A, B, C, D) with the corresponding text\n",
    "    for label, text in zip(choices_label, choices_text):\n",
    "        formatted_choices.append(f\"{label}. {text}\")\n",
    "        \n",
    "    # Join the choices with newlines to make them easy for the model to read\n",
    "    choices_block = \"\\n\".join(formatted_choices)\n",
    "    \n",
    "    # 4. Construct the full 'instruction' prompt\n",
    "    instruction = (\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Choices:\\n{choices_block}\\n\\n\"\n",
    "        \"Please select the letter (A, B, C, or D) that represents the correct answer.\"\n",
    "    )\n",
    "    \n",
    "    # 5. Determine the correct 'response'\n",
    "    \n",
    "    # Find the index of the answer key (e.g., 'B' is at index 1)\n",
    "    answer_index = choices_label.index(answer_key)\n",
    "    \n",
    "    # Get the text corresponding to the answer key\n",
    "    correct_answer_text = choices_text[answer_index]\n",
    "    \n",
    "    # The response should include the key and the full text for a complete answer\n",
    "    response = f\"Correct Answer: {answer_key}. {correct_answer_text}\"\n",
    "    \n",
    "    # 6. Return the final SFT dictionary\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"response\": response,\n",
    "        \"source\": \"arc\"\n",
    "    }\n",
    "\n",
    "def format_hotpot(example):\n",
    "    context_text = \"\\n\".join(example[\"context\"][\"sentences\"][0]) if \"context\" in example and isinstance(example[\"context\"], dict) else \"\"\n",
    "    response = f\"Answer: {example['answer']}\\n\\nContext:\\n{context_text}\"\n",
    "    return {\"instruction\": example[\"question\"], \"response\": response}\n",
    "\n",
    "\n",
    "def format_gpt4(example):\n",
    "    instruction, response = None, None\n",
    "\n",
    "    # Check for the 'conversations' key typical of OpenThoughts structure\n",
    "    if 'items' in example and isinstance(example['items'], list):\n",
    "        # The user's instruction is the 'value' of the first 'user' turn\n",
    "        # 1. Extract Instruction (User's turn)\n",
    "        user_turn = next((c for c in example['items'] if c['from'] == 'human'), None)\n",
    "        if user_turn:\n",
    "            instruction = user_turn.get('value')\n",
    "\n",
    "        # 2. Extract Response (Assistant's turn)\n",
    "        assistant_turn = next((c for c in example['items'] if c['from'] == 'gpt'), None)\n",
    "        if assistant_turn:\n",
    "            response = assistant_turn.get('value')\n",
    "    \n",
    "    \n",
    "    return {\"instruction\": instruction, \"response\": response, \"source\": \"sharegpt4\"}    \n",
    "    \n",
    "\n",
    "#  EXTRACTION FUNCTIONS END.\n",
    "\n",
    "# --- 1. Load Stable Datasets and Inspect ---\n",
    "\n",
    "print(\"üì• Starting dataset loading process and inspection...\")\n",
    "\n",
    "\n",
    "# Set a consistent seed for reproducible random sampling\n",
    "SEED = 42 \n",
    "\n",
    "def load_and_random_select(dataset_name, split_name, percentage, config_name=None):\n",
    "    \"\"\"Loads a split, shuffles it, and selects the specified percentage of entries.\"\"\"\n",
    "    print(f\"\\n-> Loading and selecting {percentage*100:.0f}% randomly from {dataset_name} ({split_name})\")\n",
    "    \n",
    "    # 1. Load the full split\n",
    "    if config_name:\n",
    "        ds_full = load_dataset(dataset_name, config_name, split=split_name)\n",
    "    else:\n",
    "        ds_full = load_dataset(dataset_name, split=split_name)\n",
    "    \n",
    "    # Calculate the number of entries to select\n",
    "    num_to_select = int(len(ds_full) * percentage)\n",
    "    \n",
    "    # 2. Shuffle the dataset and select the required number of entries\n",
    "    # The 'seed' makes the random selection reproducible\n",
    "    ds_random = ds_full.shuffle(seed=SEED).select(range(num_to_select))\n",
    "    \n",
    "    return ds_random\n",
    "\n",
    "\n",
    "#Conversational tone / flow  Ultrachat, Dolly 45 %  Teaches helpful, polite phrasing and structure\n",
    "\n",
    "#dolly = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train[:80%]\")\n",
    "dolly = load_and_random_select(\"databricks/databricks-dolly-15k\", \"train\", 0.15)\n",
    "inspect_random_entry(\"databricks/databricks-dolly-15k\", dolly)\n",
    "\n",
    "#ultrachat = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft[:10%]\")\n",
    "ultrachat = load_and_random_select(\"HuggingFaceH4/ultrachat_200k\", \"train_sft\", 0.01)\n",
    "inspect_random_entry(\"HuggingFaceH4/ultrachat_200k\", ultrachat)\n",
    "\n",
    "# Structured reasoning (CoT) Open-Thoughts, GSM8K, MATH 35 % Injects step-by-step clarity and logical progression\n",
    "\n",
    "#cot_thoughts = load_dataset(\"open-thoughts/open-thoughts-114k\", split=\"train[:21%]\")\n",
    "cot_thoughts = load_and_random_select(\"open-thoughts/open-thoughts-114k\", \"train\", 0.40)\n",
    "inspect_random_entry(\"open-thoughts/open-thoughts-114k\", cot_thoughts)\n",
    "\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\") \n",
    "inspect_random_entry(\"openai/gsm8k\", gsm8k)\n",
    "\n",
    "math_ds = load_dataset(\"HuggingFaceH4/math\", split=\"train\")\n",
    "inspect_random_entry(\"HuggingFaceH4/math\", math_ds)\n",
    "\n",
    "# Instruction diversity / broad generality Alpaca, ARC, BoolQ 15 % Keeps model generalist and able to follow any prompt\n",
    "#alpaca = load_dataset(\"tatsu-lab/alpaca\", split=\"train[:15%]\")\n",
    "alpaca = load_and_random_select(\"tatsu-lab/alpaca\", \"train\", 0.05)\n",
    "inspect_random_entry(\"tatsu-lab/alpaca\", alpaca)\n",
    "\n",
    "#boolq = load_dataset(\"google/boolq\", split=\"train[:30%]\")\n",
    "boolq = load_and_random_select(\"google/boolq\", \"train\", 0.30)\n",
    "inspect_random_entry(\"google/boolq\", boolq)\n",
    "\n",
    "arc = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\", split=\"train\")\n",
    "inspect_random_entry(\"allenai/ai2_arc\", arc)\n",
    "\n",
    "# Human-preferred style LMSYS winners 5 % ‚ÄúStyle anchor‚Äù for alignment and empathy\n",
    "#lmsys_conv_raw = load_dataset(\"lmsys/chatbot_arena_conversations\", split=\"train[:15%]\") \n",
    "lmsys_conv_raw = load_and_random_select(\"lmsys/chatbot_arena_conversations\", \"train\", 0.08)\n",
    "inspect_random_entry(\"lmsys/chatbot_arena_conversations\", lmsys_conv_raw)\n",
    "\n",
    "\n",
    "# lmsys/sharegpt4-dataset (subset)\n",
    "#sharegpt = load_dataset(\"anon8231489123/ShareGPT_Vicuna_unfiltered\", split=\"train[:3%]\")\n",
    "#sharegpt = load_dataset(\"LDJnr/ShareGPT-processed\", split=\"train[:5%]\")\n",
    "#sharegpt = load_dataset(\"lmsys/sharegpt4-dataset\", split=\"train[:5%]\")\n",
    "#inspect_random_entry(\"lmsys/sharegpt4-dataset\", sharegpt)\n",
    "\n",
    "sharegpt4 = load_dataset(\n",
    "    \"openchat/openchat_sharegpt4_dataset\",\n",
    "    data_files=\"sharegpt_gpt4.json\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "inspect_random_entry(\"openchat/openchat_sharegpt4_dataset/sharegpt_gpt4.json\", sharegpt4, force_disp = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. APPLY FORMATTERS ---\n",
    "\n",
    "print(\"\\nüß† Applying OpenThoughts formatter...\")\n",
    "cot_thoughts_formatted = cot_thoughts.map(format_OpenThoughts, remove_columns=cot_thoughts.column_names)\n",
    "inspect_formatted_sft(\"cot_thoughts_formatted\", cot_thoughts_formatted)\n",
    "\n",
    "print(\"\\nüß† Applying gsm8k formatter...\")\n",
    "gsm8k_formatted = gsm8k.map(format_GSM8K, remove_columns=gsm8k.column_names)\n",
    "inspect_formatted_sft(\"gsm8k_formatted\", gsm8k_formatted, 2, 200)\n",
    "\n",
    "print(\"\\nüß† Applying LMSYS winner extraction logic...\")\n",
    "lmsys_conv_formatted = lmsys_conv_raw.map(extract_lmsys_winner, remove_columns=lmsys_conv_raw.column_names)\n",
    "inspect_formatted_sft(\"lmsys_conv_formatted\", lmsys_conv_formatted)\n",
    "\n",
    "print(\"\\nüß† Applying dolly formatter...\")\n",
    "dolly_formatted = dolly.map(format_dolly, remove_columns=dolly.column_names)\n",
    "inspect_formatted_sft(\"dolly_formatted\", dolly_formatted)\n",
    "\n",
    "print(\"\\nüß† Applying ultrachat formatter...\")\n",
    "ultrachat_formatted = ultrachat.map(format_ultrachat, remove_columns=ultrachat.column_names)\n",
    "inspect_formatted_sft(\"ultrachat_formatted\", ultrachat_formatted)\n",
    "\n",
    "print(\"\\nüß† Formatting math formatter...\")\n",
    "math_formatted = math_ds.map(format_math, remove_columns=math_ds.column_names)\n",
    "inspect_formatted_sft(\"math_formatted\", math_formatted)\n",
    "\n",
    "print(\"\\nüß† Formatting alpaca formatter...\")\n",
    "alpaca_formatted = alpaca.map(format_alpaca, remove_columns=alpaca.column_names)\n",
    "inspect_formatted_sft(\"alpaca_formatted\", alpaca_formatted)\n",
    "\n",
    "print(\"\\nüß† Formatting boolq formatter...\")\n",
    "boolq_formatted = boolq.map(format_boolq, remove_columns=boolq.column_names)\n",
    "inspect_formatted_sft(\"boolq_formatted\", boolq_formatted)\n",
    "\n",
    "print(\"\\nüß† Formatting arc formatter...\")\n",
    "arc_formatted = arc.map(format_arc, remove_columns=arc.column_names)\n",
    "inspect_formatted_sft(\"arc_formatted\", arc_formatted)\n",
    "\n",
    "print(\"\\nüß† Formatting arc formatter...\")\n",
    "gpt4_formatted = sharegpt4.map(format_gpt4, remove_columns=sharegpt4.column_names)\n",
    "inspect_formatted_sft(\"gpt4_formatted\", gpt4_formatted, force_disp = False)\n",
    "\n",
    "# --- 3.  Merge Remaining Datasets ---\n",
    "\n",
    "formatted_datasets = []\n",
    "\n",
    "formatted_datasets.extend([\n",
    "    cot_thoughts_formatted,\n",
    "    #gsm8k_formatted,\n",
    "    lmsys_conv_formatted,\n",
    "    dolly_formatted,\n",
    "    ultrachat_formatted,\n",
    "    #math_formatted,\n",
    "    alpaca_formatted,\n",
    "    boolq_formatted,\n",
    "    arc_formatted,\n",
    "    gpt4_formatted,\n",
    "])\n",
    "\n",
    "\n",
    "mixed = concatenate_datasets(formatted_datasets).shuffle(seed=42)\n",
    "\n",
    "# --- 4. Quality Filter (Crucial step to remove null/empty entries) ---\n",
    "print(\"üóëÔ∏è Applying quality filter...\")\n",
    "\n",
    "def filter_null_or_empty(example):\n",
    "    inst = example.get(\"instruction\")\n",
    "    resp = example.get(\"response\")\n",
    "    \n",
    "    if not isinstance(inst, str) or not isinstance(resp, str):\n",
    "        return False\n",
    "    if len(inst.strip()) < 5 or len(resp.strip()) < 2:\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "mixed = mixed.filter(filter_null_or_empty)\n",
    "\n",
    "\n",
    "MAX_SAMPLES = 38000 \n",
    "\n",
    "# 1. Shuffle the dataset first (use a seed for reproducibility)\n",
    "shuffled_dataset = mixed.shuffle(seed=42)\n",
    "\n",
    "# 2. Then, select the first N samples from the now-shuffled dataset\n",
    "dataset_random = shuffled_dataset.select(range(min(MAX_SAMPLES, len(shuffled_dataset))))\n",
    "\n",
    "# take all of gsmk8 math\n",
    "# combined_dataset = concatenate_datasets([dataset_random, gpt4_formatted, gsm8k_formatted, math_formatted ])\n",
    "combined_dataset = concatenate_datasets([dataset_random, gsm8k_formatted, math_formatted ])\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "MAX_SEQ_LEN = 4096\n",
    "\n",
    "# Define your custom system prompt\n",
    "CUSTOM_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a highly professional, concise technical expert across modern computing domains ‚Äî \n",
    "including software architecture, cloud infrastructure, data systems, machine learning, and applied AI.\n",
    "\n",
    "Your task is to:\n",
    "- Answer the user‚Äôs question using the provided CONTEXT as your primary source.\n",
    "- If the CONTEXT does not contain enough information, use your own knowledge,\n",
    "  but clearly distinguish between context-based and general reasoning.\n",
    "\n",
    "Your responses must be:\n",
    "- Structured ‚Äî use clear formatting and logical reasoning.\n",
    "- Contextual ‚Äî rely only on the information available.\n",
    "- Concise ‚Äî eliminate filler words while preserving precision.\n",
    "- Aligned with industry best practices ‚Äî modern, reproducible, and standards-based.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Just load the tokenizer ‚Äî no GPU or model weights needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"unsloth/gpt-oss-20b-unsloth-bnb-4bit\",\n",
    "    use_fast=True,      # Use Fast tokenizer\n",
    "    trust_remote_code=True,  # Required for Unsloth custom templates\n",
    ")\n",
    "\n",
    "\n",
    "# Define the filtering function\n",
    "def is_length_within_limit(example):\n",
    "    # Create a Harmony-format conversation\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": CUSTOM_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": example.get(\"instruction\", \"\")},\n",
    "        {\"role\": \"assistant\", \"content\": example.get(\"response\", \"\")},\n",
    "    ]\n",
    "    wrapped = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=False,\n",
    "        tokenize=True,\n",
    "    )\n",
    "    #print(wrapped)\n",
    "    token_count = len(wrapped[\"input_ids\"]) if isinstance(wrapped, dict) else len(wrapped)\n",
    "    return token_count <= MAX_SEQ_LEN\n",
    "\n",
    "\n",
    "\n",
    "# 1. Use the .filter() method which returns a new Dataset object\n",
    "filtered_dataset = combined_dataset.filter(\n",
    "    is_length_within_limit,\n",
    "    num_proc=4 # Use multiple processes to speed up tokenization/filtering\n",
    ")\n",
    "\n",
    "# 2. Now you can safely call .shuffle() on the Dataset object\n",
    "final_dataset_random = filtered_dataset.shuffle(seed=42)\n",
    "\n",
    "print(\"\\n‚úÖ Final dataset successfully filtered and shuffled.\")\n",
    "\n",
    "\n",
    "# Prints parts of the  datasets with chat template\n",
    "def inspect_formatted_sft(ds_name, ds_object, n = 2, force_disp = False):\n",
    "\n",
    "    if not force_disp:\n",
    "        if not INSPECT_ON:\n",
    "            return \n",
    "    \n",
    "    for i, entry in enumerate(ds_object):\n",
    "        if i > n:\n",
    "            break\n",
    "        print(f\"--- Entry {i+1} ---\")\n",
    "\n",
    "            # Create a Harmony-format conversation\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": CUSTOM_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": entry.get(\"instruction\", \"\")},\n",
    "            {\"role\": \"assistant\", \"content\": entry.get(\"response\", \"\")},\n",
    "        ]\n",
    "        wrapped = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=False,\n",
    "            tokenize=False,\n",
    "        )\n",
    "        \n",
    "        print(f\"Message with chat template: {wrapped}...\") \n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "inspect_formatted_sft(\"final_dataset_random\", final_dataset_random, force_disp = True)\n",
    "\n",
    "\n",
    "# Analysis: Getting the Source Statistics ---\n",
    "print(\"\\nüìä Analyzing Sources in Final Dataset...\")\n",
    "\n",
    "# Extract the 'source' column into a list\n",
    "sources_list = final_dataset_random['source']\n",
    "\n",
    "# Get the total size of the final dataset\n",
    "final_dataset_size = len(final_dataset_random)\n",
    "\n",
    "# Convert the list to a Pandas Series and count the unique values (This gives the 'Count' column)\n",
    "source_counts = pd.Series(sources_list).value_counts()\n",
    "\n",
    "# Calculate the total number of unique sources\n",
    "total_unique_sources = len(source_counts)\n",
    "\n",
    "# --- NEW LOGIC: Create a DataFrame for summary and add the Percentage column ---\n",
    "\n",
    "# Convert the Series to a DataFrame\n",
    "summary_df = source_counts.rename('Count').to_frame()\n",
    "\n",
    "# Calculate the percentage\n",
    "summary_df['Percentage'] = (summary_df['Count'] / final_dataset_size) * 100\n",
    "\n",
    "# Format the Percentage column for clean display\n",
    "summary_df['Percentage'] = summary_df['Percentage'].map('{:.2f}%'.format)\n",
    "\n",
    "# --- Printing the Summary ---\n",
    "print(\"-\" * 50)\n",
    "print(f\"Final Dataset Size: {final_dataset_size} entries\")\n",
    "print(f\"Total Unique Sources Found: {total_unique_sources}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Count and Percentage of Data Entries per Source:\")\n",
    "print(summary_df.to_string()) # Print the DataFrame with both Count and Percentage\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. Final Output ---\n",
    "# Save as JSONL for Unsloth\n",
    "df = pd.DataFrame(final_dataset_random)\n",
    "df.to_json(\"train_sft_final.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "print(f\"\\nüéâ SUCCESS! Final SFT dataset created: train_sft_final.jsonl\")\n",
    "print(f\"Total samples after filtering: {len(final_dataset_random)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c550bff-0143-4cfe-ab14-887fb1f1a880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Token Length (Instruction + Response) per Source:\n",
      "-------------------------------------------------------\n",
      "source\n",
      "OpenThoughts    3872\n",
      "sharegpt4       3728\n",
      "dolly           3337\n",
      "math            2445\n",
      "ultrachat       2366\n",
      "lmsys_conv      1256\n",
      "boolq            580\n",
      "alpaca           444\n",
      "GSM8K            409\n",
      "arc              235\n",
      "Name: total_tokens, dtype: int64\n",
      "Count of Entries with Token Length > 4096 per Source:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Alternatively, a cleaner map that keeps only source and tokens\n",
    "def prepare_data_for_analysis(example, tokenizer):\n",
    "    combined_text = example['instruction'] + \" \" + example['response']\n",
    "    tokenized = tokenizer(combined_text, truncation=False, return_length=True)\n",
    "    return {\n",
    "        'source': example['source'], # Assuming you have a 'source' column\n",
    "        'total_tokens': tokenized['length'][0]\n",
    "    }\n",
    "\n",
    "analysis_dataset = final_dataset_random.map(\n",
    "    lambda x: prepare_data_for_analysis(x, tokenizer),\n",
    "    batched=False, # Process one example at a time\n",
    "    num_proc=4,\n",
    "    remove_columns=final_dataset_random.column_names # Keep only the two new columns\n",
    ")\n",
    "\n",
    "# Convert the analysis dataset to a Pandas DataFrame\n",
    "analysis_df = analysis_dataset.to_pandas()\n",
    "\n",
    "# Group by the 'source' column and find the maximum 'total_tokens'\n",
    "max_lengths_by_source = analysis_df.groupby('source')['total_tokens'].max().sort_values(ascending=False)\n",
    "\n",
    "## Output the result\n",
    "print(\"Maximum Token Length (Instruction + Response) per Source:\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(max_lengths_by_source)\n",
    "\n",
    "\n",
    "# Convert to Pandas for aggregation\n",
    "analysis_df = analysis_dataset.to_pandas()\n",
    "\n",
    "# Filter for entries where token length is greater than the threshold\n",
    "large_entries_df = analysis_df[analysis_df['total_tokens'] > MAX_SEQ_LEN]\n",
    "\n",
    "#  Group by 'source' and count the number of entries\n",
    "count_by_source = large_entries_df.groupby('source').size().sort_values(ascending=False)\n",
    "\n",
    "# Print the final result\n",
    "print(f\"Count of Entries with Token Length > {MAX_SEQ_LEN} per Source:\")\n",
    "print(count_by_source)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb77e2-9b61-4c38-a07e-877c39b44649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
